{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01ed1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import layers, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02a127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path):\n",
    "    samples, labels = [], []\n",
    "    model = yamnet_frames_model(Params())\n",
    "    model.load_weights(YAMNET_PATH)\n",
    "    for cls in os.listdir(path):\n",
    "        for sound in tqdm(os.listdir(os.path.join(path, cls))):\n",
    "            wav = librosa.load(os.path.join(os.path.join(path, cls, sound)), sr=16000)[0].astype(np.float64)\n",
    "\n",
    "            #Here you can add preprocessing, augmentations, silence removal, etc.\n",
    "\n",
    "            for feature in model(wav)[1]:\n",
    "                samples.append(feature)\n",
    "                labels.append(cls)\n",
    "    samples = np.asarray(samples)\n",
    "    labels = np.asarray(labels)\n",
    "    return samples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad6ac020",
   "metadata": {},
   "outputs": [],
   "source": [
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4984427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map_path = yamnet_model.class_map_path().numpy().decode('utf-8')\n",
    "class_names =list(pd.read_csv(class_map_path)['display_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fedfc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaspfiles = glob.glob(\"Sounds/gaspSounds/*\")\n",
    "coughfiles = glob.glob(\"Sounds/coughSounds/*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3762b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, labels = [], []\n",
    "for file in gaspfiles:\n",
    "    try:\n",
    "        wav_data = librosa.load(file,sr=16000)[0].astype(np.float32)\n",
    "    except:\n",
    "        continue\n",
    "    for feature in yamnet_model(wav_data)[1]:\n",
    "        samples.append(feature)\n",
    "        labels.append(\"gasp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93779344",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in coughfiles:\n",
    "    try:\n",
    "        wav_data = librosa.load(file,sr=16000)[0].astype(np.float32)\n",
    "    except:\n",
    "        continue\n",
    "    for feature in yamnet_model(wav_data)[1]:\n",
    "        samples.append(feature)\n",
    "        labels.append(\"cough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43e7db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.asarray(samples)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fec119eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(num_classes,\n",
    "                  num_hidden=64,\n",
    "                  activation='softmax',\n",
    "                  regularization=0.03,\n",
    "                  ):\n",
    "\n",
    "    input = layers.Input(shape=(1024,))\n",
    "    net = layers.Dense(num_hidden, activation=None, kernel_regularizer=tf.keras.regularizers.l2(regularization))(input)\n",
    "    net = layers.Dense(num_classes, activation=activation)(net)\n",
    "    model = Model(inputs=input, outputs=net)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae421ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X,\n",
    "                y,\n",
    "                fname,  # Path where to save the model\n",
    "                activation='softmax',\n",
    "                epochs=30,\n",
    "                optimizer='adam',\n",
    "                num_hidden=64,\n",
    "                batch_size=64\n",
    "                ):\n",
    "    # Encode the labels\n",
    "    encoder = LabelBinarizer()\n",
    "    labels = encoder.fit_transform(y)\n",
    "\n",
    "    # Save the names of the classes for future using.\n",
    "    np.save(fname, encoder.classes_)\n",
    "    num_classes = len(np.unique(y))\n",
    "\n",
    "    # Generate the model\n",
    "    general_model = generate_model(num_classes, num_hidden=num_hidden, activation=activation)\n",
    "    general_model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "    # Create some callbacks\n",
    "    callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=fname, monitor='val_loss', save_best_only=True),\n",
    "                 tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=15, verbose=1,\n",
    "                                                      min_lr=0.000001)]\n",
    "\n",
    "    general_model.fit(X, labels, epochs=epochs, validation_split=0.20, batch_size=batch_size,\n",
    "                      callbacks=callbacks, verbose=1)\n",
    "\n",
    "    # Load the best weights after the training.\n",
    "    general_model.load_weights(fname)\n",
    "\n",
    "    return general_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d87fd6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 3.2746 - accuracy: 0.8149 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 53ms/step - loss: 3.2290 - accuracy: 0.8192 - val_loss: 3.4053 - val_accuracy: 0.4391 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "19/28 [===================>..........] - ETA: 0s - loss: 1.7936 - accuracy: 0.8923"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 1.6884 - accuracy: 0.8895 - val_loss: 1.9150 - val_accuracy: 0.5931 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "19/28 [===================>..........] - ETA: 0s - loss: 1.0155 - accuracy: 0.8931"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 34ms/step - loss: 0.9606 - accuracy: 0.8889 - val_loss: 1.1590 - val_accuracy: 0.6483 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "18/28 [==================>...........] - ETA: 0s - loss: 0.6906 - accuracy: 0.8932"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 0.6566 - accuracy: 0.8906 - val_loss: 1.1285 - val_accuracy: 0.6897 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "21/28 [=====================>........] - ETA: 0s - loss: 0.5237 - accuracy: 0.8936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 0.5109 - accuracy: 0.8969 - val_loss: 1.0482 - val_accuracy: 0.6322 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.9021 - val_loss: 1.1862 - val_accuracy: 0.5494 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "21/28 [=====================>........] - ETA: 0s - loss: 0.3723 - accuracy: 0.9085"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 59ms/step - loss: 0.3742 - accuracy: 0.9079 - val_loss: 1.0144 - val_accuracy: 0.5471 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.9033 - val_loss: 1.2259 - val_accuracy: 0.4667 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "21/28 [=====================>........] - ETA: 0s - loss: 0.3398 - accuracy: 0.8981"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 0.3273 - accuracy: 0.9062 - val_loss: 1.0039 - val_accuracy: 0.6138 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "23/28 [=======================>......] - ETA: 0s - loss: 0.3141 - accuracy: 0.9049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 31ms/step - loss: 0.3124 - accuracy: 0.9044 - val_loss: 0.9995 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "21/28 [=====================>........] - ETA: 0s - loss: 0.3015 - accuracy: 0.9115"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 30ms/step - loss: 0.3072 - accuracy: 0.9085 - val_loss: 0.8951 - val_accuracy: 0.5885 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "21/28 [=====================>........] - ETA: 0s - loss: 0.3062 - accuracy: 0.9152"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 31ms/step - loss: 0.3137 - accuracy: 0.9056 - val_loss: 0.8522 - val_accuracy: 0.6253 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3098 - accuracy: 0.9044 - val_loss: 0.9039 - val_accuracy: 0.6529 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2837 - accuracy: 0.9119 - val_loss: 1.1647 - val_accuracy: 0.5379 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2896 - accuracy: 0.9039 - val_loss: 1.4850 - val_accuracy: 0.5126 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3110 - accuracy: 0.9096 - val_loss: 1.1474 - val_accuracy: 0.5931 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.9125 - val_loss: 1.1085 - val_accuracy: 0.6437 - lr: 0.0010\n",
      "Epoch 18/30\n",
      " 1/28 [>.............................] - ETA: 0s - loss: 0.2943 - accuracy: 0.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 60ms/step - loss: 0.2879 - accuracy: 0.9067 - val_loss: 0.7621 - val_accuracy: 0.7264 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.9096 - val_loss: 1.9543 - val_accuracy: 0.6966 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3409 - accuracy: 0.9090 - val_loss: 1.3634 - val_accuracy: 0.6322 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2929 - accuracy: 0.9113 - val_loss: 0.8918 - val_accuracy: 0.6460 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2665 - accuracy: 0.9102 - val_loss: 1.2791 - val_accuracy: 0.5034 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2829 - accuracy: 0.9148 - val_loss: 1.8174 - val_accuracy: 0.5678 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3609 - accuracy: 0.9142 - val_loss: 1.5033 - val_accuracy: 0.6989 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.9056 - val_loss: 0.9318 - val_accuracy: 0.6391 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2663 - accuracy: 0.9067 - val_loss: 1.0685 - val_accuracy: 0.6069 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2673 - accuracy: 0.9200 - val_loss: 0.7797 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2832 - accuracy: 0.9142 - val_loss: 2.2650 - val_accuracy: 0.4920 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.9096 - val_loss: 2.1602 - val_accuracy: 0.6276 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.9159 - val_loss: 1.2496 - val_accuracy: 0.6483 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "model2 = train_model(samples, labels, \"tmp.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21bdd8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x28719c411f0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a4cea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_data = librosa.load(file,sr=16000)[0].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b9a4f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReduceMeanLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, axis=0, **kwargs):\n",
    "    super(ReduceMeanLayer, self).__init__(**kwargs)\n",
    "    self.axis = axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0dd32124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sounds/burpSounds\\\\19tPF3TY3g0_split.wav'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = glob.glob(\"Sounds/burpSounds/*\")[0]\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bdb21569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp.pb\\assets\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = \"tmp.pb\"\n",
    "input_segment = tf.keras.layers.Input(shape=(), dtype=tf.float32, name='audio')\n",
    "embedding_extraction_layer = hub.KerasLayer('https://tfhub.dev/google/yamnet/1',\n",
    "                                            trainable=False, name='yamnet')\n",
    "_, embeddings_output, _ = embedding_extraction_layer(input_segment)\n",
    "serving_outputs = model2(embeddings_output)\n",
    "serving_outputs = ReduceMeanLayer(axis=0, name='classifier')(serving_outputs)\n",
    "serving_model = tf.keras.Model(input_segment, serving_outputs)\n",
    "serving_model.save(saved_model_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d28fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_model = tf.saved_model.load(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c39af03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[YAMNet] The main sound is: Silence (0.30727311968803406)\n"
     ]
    }
   ],
   "source": [
    "testing_wav_data = librosa.load(gaspfiles[0],sr=16000)[0].astype(np.float32)\n",
    "reloaded_results = reloaded_model(testing_wav_data)\n",
    "class_scores = tf.reduce_mean(scores, axis=0)\n",
    "top_class = tf.math.argmax(class_scores)\n",
    "inferred_class = class_names[top_class]\n",
    "top_score = class_scores[top_class]\n",
    "print(f'[YAMNet] The main sound is: {inferred_class} ({top_score})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e758b06e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'general_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22600\\3042189789.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgeneral_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'general_model' is not defined"
     ]
    }
   ],
   "source": [
    "general_model.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bd470eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cough', 'gasp'], dtype='<U5')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"tmp.pb.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a5f0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
