{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ec293b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chloe\\anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.io import wavfile\n",
    "import soundfile as sf\n",
    "import resampy\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfd7ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n",
    "def class_names_from_csv(class_map_csv_text):\n",
    "    class_names = []\n",
    "    with tf.io.gfile.GFile(class_map_csv_text) as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        class_names.append(row['display_name'])\n",
    "\n",
    "    return class_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550ba3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \"\"\"Resample waveform if required.\"\"\"\n",
    "def ensure_sample_rate(original_sample_rate, waveform, desired_sample_rate=16000):\n",
    "    if original_sample_rate != desired_sample_rate:\n",
    "        desired_length = int(round(float(len(waveform)) / original_sample_rate * desired_sample_rate))\n",
    "        waveform = scipy.signal.resample(waveform, desired_length)\n",
    "    return desired_sample_rate, waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de1ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    os.environ[\"TFHUB_CACHE_DIR\"] = \"\\\\Users\\\\chloe\\\\Documents\\\\tensorflow\"\n",
    "    model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
    "    class_map_path = model.class_map_path().numpy()\n",
    "    class_names = class_names_from_csv(class_map_path)\n",
    "    return model, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8654255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000.0\n",
    "\"\"\"\n",
    "Classifies audio data according to the AudioSet Yamnet Data\n",
    "Code is adapted from the interference.py code from the official documentation \n",
    "If the wave is not in the right shape or not sampled in the right sampling rate, the wave is fixed so it fits the data\n",
    "Then the wave is classified.\n",
    "\n",
    "The output of the model is a matrix of (# time frames, # classes) classifier scores; the documentation recommends taking the mean across the 0th axis to get an average across time\n",
    "Thus, we can see the average classifier score across time, not just for a specific timeframe. \n",
    "\n",
    "Returned are the means and standard deviations.\n",
    "\"\"\"\n",
    "def getClassifications(model,wav_data,sr):\n",
    "    waveform = wav_data / 32768.0  # Convert to [-1.0, +1.0]\n",
    "    waveform = waveform.astype('float32')\n",
    "    if len(waveform.shape) > 1:\n",
    "        waveform = np.mean(waveform, axis=1)\n",
    "    if sr != SAMPLE_RATE:\n",
    "        waveform = resampy.resample(waveform, sr, SAMPLE_RATE)\n",
    "    \n",
    "    scores, embeddings, spectrogram = model(waveform)\n",
    "    prediction = np.mean(scores, axis=0) #Averaged across time\n",
    "    std = np.mean(scores,axis=0)\n",
    "    return prediction,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "524e23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "After the model scores all the classes, this function gets the top five classifications and matches them to the class names.\n",
    "The returned result is an array with (class name,probablity) for the top five. \n",
    "\"\"\"\n",
    "def getTopFive(predictions):\n",
    "    top5_i = np.argsort(predictions)[::-1][:5]\n",
    "    toRet = []\n",
    "    for i in top5_i:\n",
    "        toRet.append(class_names[i])\n",
    "        toRet.append(predictions[i])\n",
    "    return toRet\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b2d4cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model,class_names= getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dbdf00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNET_9C4\\T000146.wav\n",
      "PNET_9C4\\T000246.wav\n",
      "PNET_9C4\\T000346.wav\n",
      "PNET_9C4\\T000446.wav\n",
      "PNET_9C4\\T000460.wav\n",
      "PNET_9C4\\T000461.wav\n",
      "PNET_9C4\\T000462.wav\n",
      "PNET_9C4\\T000463.wav\n",
      "PNET_9C4\\T000464.wav\n",
      "PNET_9C4\\T000465.wav\n",
      "PNET_9C4\\T000466.wav\n",
      "PNET_9C4\\T000467.wav\n",
      "PNET_9C4\\T000468.wav\n",
      "PNET_9C4\\T000469.wav\n",
      "PNET_9C4\\T000546.wav\n",
      "PNET_9C4\\T000646.wav\n",
      "PNET_9C4\\T000746.wav\n",
      "PNET_9C4\\T000846.wav\n",
      "PNET_9C4\\T000946.wav\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f = open(\"../../../Desktop/fwdchickenvocalisationspectralentropy/fullband_entropies.csv\")\n",
    "reader = csv.reader(f)\n",
    "entropies = {}\n",
    "for line in reader:\n",
    "    if \"46\" in line[0]: print(line[0])\n",
    "    entropies[line[0]] = float(line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c845811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"PNET_9C4\\T000046.wav\" in entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98143756",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNET_9C4\\T000046.wav\n",
      "PNET_9C4\\T000060.wav\n",
      "PNET_9C4\\T000076.wav\n",
      "PNET_9C4\\T000082.wav\n",
      "PNET_9C4\\T000113.wav\n",
      "PNET_9C4\\T000114.wav\n",
      "PNET_9C4\\T000120.wav\n",
      "PNET_9C4\\T000121.wav\n",
      "PNET_9C4\\T000137.wav\n",
      "PNET_9C4\\T000138.wav\n",
      "PNET_9C4\\T000145.wav\n",
      "PNET_9C4\\T000148.wav\n",
      "PNET_9C4\\T000247.wav\n",
      "PNET_9C4\\T000550.wav\n",
      "PNET_9C4\\T000593.wav\n",
      "PNET_9C4\\T000598.wav\n",
      "PNET_9C4\\T000754.wav\n",
      "PNET_9C4\\T000769.wav\n",
      "PNET_9C4\\T000836.wav\n",
      "PNET_9C4\\T000889.wav\n",
      "PNET_9C4\\T000945.wav\n",
      "PNET_9C4\\T000970.wav\n",
      "PNET_9C4\\T000981.wav\n",
      "PNET_9C4\\T000996.wav\n",
      "PNET_9C4\\T001000.wav\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"../../../Desktop/fwdchickenvocalisationspectralentropy/PNET_9C4/*\")\n",
    "pairs = []\n",
    "for file in files:\n",
    "    data,sr = sf.read(file, dtype=np.int16)\n",
    "    p,s = getClassifications(model,data,sr)\n",
    "    prediction = getTopFive(p)\n",
    "    filen = file.split(\"/\")[-1]\n",
    "    if filen not in entropies:\n",
    "        print(filen)\n",
    "        continue\n",
    "    pairs.append((entropies[filen],prediction[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4a2c2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"Sounds/*/*_split.wav\")\n",
    "f = open(\"sound_metadata.csv\",'w')\n",
    "writer = csv.writer(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afda32bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    label = file.split(\"\\\\\")[1].split(\"Sounds\")[0]\n",
    "    writer.writerow([file,label])\n",
    "f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc09521",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"../..//../Desktop/audio/*.wav\")\n",
    "\n",
    "false = 0\n",
    "total = 0\n",
    "others = []\n",
    "dd = {}\n",
    "for file in files:\n",
    "    id_ =  file.split(\"/\")[-1].split(\"-\")[1]\n",
    "    if id_ not in ids: continue\n",
    "    split, sr = splitFile(file,2)\n",
    "    for el in split:\n",
    "        if prediction[0] in names: false +=1\n",
    "        else:\n",
    "            others.append(prediction[0])\n",
    "        if prediction[0] not in dd: dd[prediction[0]]=[]\n",
    "        dd[prediction[0]].append(file)\n",
    "        total +=1\n",
    "false, total, false/total, (total-false)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c204fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "x = Counter(others)\n",
    "x.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e60ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd['Water']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d49f4ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "total = 0\n",
    "for i in range(len(split)):\n",
    "    section = split[i]\n",
    "    p,s = getClassifications(model,section,sr)\n",
    "    print(getTopFive(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cff701",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Need index of Cough ID in class names (to get probability) for cough profile. I assume this won't change from run to run, but just in case, don't want to hardcode it\n",
    "Also, if we decide to add more categories as labels to cough (throat clearing, for example), this will come in handy\n",
    "\"\"\"\n",
    "def getCoughIndex():\n",
    "    for i in range(len(class_names)):\n",
    "        if class_names[i] == \"Cough\":\n",
    "            return i\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0d58f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Takes a set of audiodata and returns probablity of cough\n",
    "\n",
    "TODO: Future versions would have timestamps, but I don't have enough coughs with timestamps to create that kind of data\n",
    "INCORPORATE standard deviations somehow\n",
    "\"\"\"\n",
    "COUGH_INDEX = getCoughIndex()\n",
    "def getCoughProfile(audiodata):\n",
    "    results = []\n",
    "    for frame in audiodata:\n",
    "        p,s = getClassifications(model,frame,sr)\n",
    "        results.append(p[COUGH_INDEX])\n",
    "    \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a09b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files  = glob.glob(\"../..//../Desktop/Trainingdata/audio_data/cough/*.wav\")[0:25]\n",
    "data = []\n",
    "for file in files:\n",
    "    split,sr = splitFile(file,2)\n",
    "    data.extend(split)\n",
    "getCoughProfile(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b72b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "jsondata = json.load(open(\"Datasets/ontology.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f701d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for el in jsondata:\n",
    "    id = el['id']\n",
    "    name = el['name']\n",
    "    children = el['child_ids']\n",
    "    d[id] = (children,name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf95f418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Human voice',\n",
       " 'Speech',\n",
       " 'Male speech, man speaking',\n",
       " 'Female speech, woman speaking',\n",
       " 'Child speech, kid speaking',\n",
       " 'Conversation',\n",
       " 'Narration, monologue',\n",
       " 'Babbling',\n",
       " 'Speech synthesizer',\n",
       " 'Shout',\n",
       " 'Bellow',\n",
       " 'Whoop',\n",
       " 'Yell',\n",
       " 'Battle cry',\n",
       " 'Children shouting',\n",
       " 'Screaming',\n",
       " 'Whispering',\n",
       " 'Laughter',\n",
       " 'Baby laughter',\n",
       " 'Giggle',\n",
       " 'Snicker',\n",
       " 'Belly laugh',\n",
       " 'Chuckle, chortle',\n",
       " 'Crying, sobbing',\n",
       " 'Baby cry, infant cry',\n",
       " 'Whimper',\n",
       " 'Wail, moan',\n",
       " 'Sigh',\n",
       " 'Singing',\n",
       " 'Choir',\n",
       " 'Yodeling',\n",
       " 'Chant',\n",
       " 'Mantra',\n",
       " 'Male singing',\n",
       " 'Female singing',\n",
       " 'Child singing',\n",
       " 'Synthetic singing',\n",
       " 'Rapping',\n",
       " 'Humming',\n",
       " 'Groan',\n",
       " 'Grunt',\n",
       " 'Yawn',\n",
       " 'Whistling',\n",
       " 'Wolf-whistling',\n",
       " 'Respiratory sounds',\n",
       " 'Breathing',\n",
       " 'Wheeze',\n",
       " 'Snoring',\n",
       " 'Gasp',\n",
       " 'Pant',\n",
       " 'Snort',\n",
       " 'Cough',\n",
       " 'Throat clearing',\n",
       " 'Sneeze',\n",
       " 'Sniff',\n",
       " 'Human locomotion',\n",
       " 'Run',\n",
       " 'Shuffle',\n",
       " 'Walk, footsteps',\n",
       " 'Digestive',\n",
       " 'Chewing, mastication',\n",
       " 'Biting',\n",
       " 'Gargling',\n",
       " 'Stomach rumble',\n",
       " 'Burping, eructation',\n",
       " 'Hiccup',\n",
       " 'Fart',\n",
       " 'Hands',\n",
       " 'Finger snapping',\n",
       " 'Clapping',\n",
       " 'Heart sounds, heartbeat',\n",
       " 'Heart murmur',\n",
       " 'Otoacoustic emission',\n",
       " 'Tinnitus, ringing in the ears',\n",
       " 'Human group actions',\n",
       " 'Clapping',\n",
       " 'Cheering',\n",
       " 'Applause',\n",
       " 'Chatter',\n",
       " 'Crowd',\n",
       " 'Hubbub, speech noise, speech babble',\n",
       " 'Booing',\n",
       " 'Children playing',\n",
       " 'Children shouting']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "children = d[\"/m/0dgw9r\"][0]\n",
    "names = []\n",
    "for el in children:\n",
    "    names.extend(get_subordinates(d,el))\n",
    "    \n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23f29699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subordinates(dictionary, label):\n",
    "    children, name = dictionary[label]\n",
    "    if children == []: return [name]\n",
    "    toRet = [name]\n",
    "    for el in children:\n",
    "        toRet.extend(get_subordinates(dictionary, el))\n",
    "    return toRet\n",
    "                \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57181933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/m/0dgw9r Human sounds\n"
     ]
    }
   ],
   "source": [
    "for key in d:\n",
    "    vals = d[key]\n",
    "    if  \"/m/09hlz4\" in vals[0]:\n",
    "        print(key, vals[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc416fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
